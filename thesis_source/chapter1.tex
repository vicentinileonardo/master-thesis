\chapter{Introduction}
\label{cha:introduction}

In this chapter we will introduce the context of the work, the problem statement, the method adopted and the personal contribution to the overall project.

\section{Context}
\label{sec:context}

[TO BE FIXED] \newline

The work described in this thesis is part of a larger project developed by a team
that aims to develop a system for reducing the carbon footprint of workloads in the cloud. 
Said system is based on the idea of \textbf{time-shifting} and \textbf{geographical shifting} of workloads to time periods and geographical regions with low carbon intensity.
As a matter of fact, nowadays, the carbon intensity of electricity varies significantly depending on the time of day and the geographical region.
Therefore, it is deemed interesting to leverage this information to schedule workloads in a way that reduces the carbon footprint of the workloads compared to a traditional scheduling approach.
Targeted workloads are the ones that are not time-sensitive but instead are quite delay-tolerant. 
In addition, workloads are also characterized by other requirements, such as Quality of Service (QoS) requirements (e.g., deadlines, maxLatency, etc.).
Indeed a \textbf{policy-driven approach} is used to encode these requirements along with schduling outcomes.


The system is designed to be used in a multi-cloud setting, 
The system is designed to be flexible and extensible, so that it can be used for different types of workloads and different cloud providers.

GOAL
The goal of the project is to employ mainly time-shifting and geographical shifting for the scheduling of workload leveraging a multi-cloud setting.
We can choose to schedule workloads in periods and regions with low carbon intensity (when renewables are plentiful). 
Therefore, targeted workloads are the ones that are not time-sensitive but instead are quite delay-tolerant. For example training a machine learning model could wait until a period of low carbon intensity. Another example is shifting video / image processing, as Google is doing.
Kubernetes is leveraged as a platform for scheduling and managing workloads on different cloud providers.
Long term goal: “Using electricity when the carbon intensity is low is the best way to ensure investment flows towards low-carbon emitting plants and away from high-carbon emitting plants”.

The project is divided into three main parts: data analysis, machine learning, and cloud infrastructure as shown in Figure \ref{fig:project_parts}.

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.25\linewidth]{images/project_parts.png}
    \caption{Project parts}
    \label{fig:project_parts}
\end{figure}

The focus of this thesis is on the cloud infrastructure part.


[TO BE ADDED]

MULTI Cloud
MULTI CLOUD RESOURCE MANAGEMENT


Computational sustainability

GreenOps

GreenOps for FinOps
(Operating for GreenOps may lead to reduced costs)

Geographical shifting and Time shifting
Carbon-aware workload scheduling
psrticular kind of workload (delay tolerant)


Cloud sustainability

Current Sustainable Cloud Computing Landscape
we are in the infrastructure tooling section
in particular scheduling (day 1 operatsion)

scaling and resource tuning are usuaully day 2 operation

the system was envisioned with this in mind and is capable of doing that



reducing the Carbon Footprint (CFP) due to
executing workloads, 
while satisfying Quality of Service (QoS)
requirements

\section{Problem statement}
\label{sec:problem}

[TO BE ADDED]

Use cases (basic ones for the beginning) higher level explanation here
first use case ("GreenOps" VM scheduling)

second: scaling down a vm 
infrastructure already put in place

the system was designed with flexibility in mind therefore a workload could be potentially anything
the condition is just to be represented in some way and have something else do certain actions based on that representation
As we will see in section XXX, the most simple of this would be K8s operators
this is described in section XYZ

\section{Method}

The method adopted in this thesis followed several principles described in this section.
First of all the main goal was to develop a solution to be integrated to be integrated into an existing platform \textbf{to support real use cases}.

Developing a real solution, integrating it on top of OSS

production-ready solution

we are on the consumer side, not on the provider side

System architecture to start with: Saima's + Krateo platform

integration into an existing platform (krateo)

leveraging krateo componenets is beneficial 

Krateo Core Provider and cdc instead of developing 1 or more K8s operators from scratch


analysis of possible solutions
implemnted poc 

Initial analysis of a solution with operators were tried

A PoC comprising 1 operator was created 
``Synchronization operation"
cons: maintainer costs

ideation and creation of architectural diagrams

tackling first use case: GreenOps scheeduling of virtual machines
but create a system that is flexible and extendible enough to be used for other use cases as well

\section{Personal contribution}

[TO BE ADDED]

The project, ideated and supervisioned by Prof. Fiore is mainly divided into 3 parts.

exploratory data analysis
data preparation

model training
model selection

infrastructure part



\newpage
